"""
–ì–ª–∞–≤–Ω—ã–π –º–æ–¥—É–ª—å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∫–æ—Ä–ø—É—Å–∞ —Ç–µ–∫—Å—Ç–æ–≤ Dante's Inferno.

–≠—Ç–æ—Ç —Å–∫—Ä–∏–ø—Ç –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –≤—Å–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã –≤ –ø–∞–ø–∫–µ corpus/
–∏ —Å–æ–∑–¥–∞—ë—Ç –æ—Ç—á—ë—Ç—ã —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∞–Ω–∞–ª–∏–∑–∞.
"""

import os
from text_utils import (
    count_words,
    count_unique_words,
    calculate_ttr,
    get_most_common_words,
    count_lines,
    average_word_length
)
from file_utils import (
    read_text_file,
    read_csv_file,
    write_csv_file,
    write_text_file,
    get_files_in_folder
)


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–æ–≥—Ä–∞–º–º—ã."""
    print("=" * 60)
    print("üìÇ –ê–Ω–∞–ª–∏–∑ –∫–æ—Ä–ø—É—Å–∞ —Ç–µ–∫—Å—Ç–æ–≤ –ì–∞–ª–∏—á–∞")
    print("=" * 60)

    
    corpus_folder = 'corpus'
    print(f"\nüîç –ü–æ–∏—Å–∫ —Ñ–∞–π–ª–æ–≤ –≤ –ø–∞–ø–∫–µ '{corpus_folder}'...")

    files = get_files_in_folder(corpus_folder, '.txt')  

    if not files:
        print("‚ùå –§–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã!")
        return

    print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(files)}")

    print("\n–°–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤:")
    for i, filename in enumerate(files, start=1):
        print(f"  {i}. {filename}")

    print("\n‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")


def analyze_single_text(filepath, filename):
    pass


def analyze_corpus(corpus_folder):
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –≤—Å–µ —Ç–µ–∫—Å—Ç—ã –≤ –ø–∞–ø–∫–µ, —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏ –≤—ã–≤–æ–¥–∏—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É.

    Args:
        corpus_folder (str): –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å —Ç–µ–∫—Å—Ç–∞–º–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 'corpus')
    """
    txt_files = get_files_in_folder(corpus_folder)
    data = []

    for filename in txt_files:
        if filename.endswith('.txt'):
            file_path = os.path.join(corpus_folder, filename)
            text = read_text_file(file_path)
            word_count_value = word_count(text)
            unique_words_value = count_unique_words(text)
            ttr_value = calculate_ttr(text)
            lines_count = count_lines(text)       
            avg_word_len = average_word_length(text)   
                  
         
            data.append([filename, word_count_value, unique_words_value, f"{ttr_value:.3f}", lines_count, f"{avg_word_len:.2f}"])

    csv_path = 'results/statistics.csv'
    headers = ['filename', 'word_count', 'unique_words', 'ttr', "lines", 'avg_word_length']
    write_csv_file(csv_path, data, headers)

    loaded_data = read_csv_file(csv_path)

    print("–î–ï–¢–ê–õ–¨–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–û –§–ê–ô–õ–ê–ú:")
    print("-" * 80)
    for row in loaded_data:
        print(f"–§–∞–π–ª: {row['filename']}")
        print(f" –°—Ç—Ä–æ–∫: {row['lines']}")
        print(f"–°–ª–æ–≤: {row['word_count']}")
        print(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: {row['unique_words']}")
        print(f"TTR: {row['ttr']}")
        print(f"–°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ —Å–ª–æ–≤–∞: {row['avg_word_length']}")
        

    loaded_data = read_csv_file(csv_path) 
    print(f"–í—Å–µ–≥–æ —Ç–µ–∫—Å—Ç–æ–≤: {len(loaded_data)}")


if __name__ == "__main__":
    analyze_corpus("corpus")



def generate_report(results, metadata):
   pass


def main():
    pass


if __name__ == "__main__":
    main()

    analyze_corpus("corpus")
